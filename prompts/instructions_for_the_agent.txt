You are assisting on an e-commerce–wide semantic + keyword search system (fashion, electronics, home-decor, beauty, groceries, gifts, etc.).
Data lives in MongoDB Atlas with OpenAI text-embedding-3-small vectors.
Your job: help implement schema normalization, Atlas Search indexes, query parsing, hybrid retrieval, reranking, facets, and pagination.

Objectives (build in this order)
Schema touch-up: add normalized fields; keep one vector per product.

Backfill script: populate new fields from existing docs.

Indexes: create Atlas Vector Search + Text/BM25+autocomplete, and B-tree filter indexes.

Query parsing: rules-based extractor for price/color/category/brand; residual text → embedding.

Hybrid search pipeline: vector + keyword branches; combine scores.

Reranking (optional): Cohere Rerank on top-K.

Facets: $searchMeta for brand/color/price buckets.

Pagination: stable sort and cursor/skip+limit.

Observability: log query → results → clicks; compute popularity boost later.

Data Model (augment existing docs — do NOT break current fields)
Add these fields (keep your existing ones like title, brand, description, images, openai_embedding_text, embedding):

{
  // Canonical numerics
  "price_inr": <number>,        // from selling_price_numeric
  "mrp_inr": <number>,          // from actual_price_numeric
  "rating_avg": <number>,       // from average_rating_numeric

  // Categorization
  "category_main": "clothing_and_accessories",  // derive from current category
  "category_leaf": "bottomwear",                // from sub_category (lowercased)

  // Attributes (flattened from product_details[])
  "attributes": {
    "style_code": "1005BLUE",
    "closure": ["Drawstring","Elastic"],
    "pockets": "Side Pockets",
    "fabric": "Cotton Blend",
    "pattern": "Solid",
    "color": "Blue",
    "size": null
  },

  // Filter helpers
  "brand_lc": "york",
  "color_lc": "blue",
  "title_autocomplete": "Solid Men Blue Track Pants",

  // Vector (single source of truth)
  "embedding": [ /* 1536-d float from text-embedding-3-small */ ]
}


Acceptance criteria

Numbers are numbers (no currency symbols/commas).

Only one vector field is used (embedding).

openai_embedding_text stays short & consistent:

"{title} | Brand: {brand} | {category_leaf} | Color: {color} | Fabric: {fabric} | Price: ₹{price_inr}"


Backfill Script (Python outline)
Generate/update new fields for all products using existing fields.
from pymongo import MongoClient
import re

client = MongoClient("<MONGODB_URI>")
col = client.db.products

def to_lc(x): return x.lower().strip() if isinstance(x, str) else None
def arr(v): 
    return [s.strip() for s in v.split(",")] if isinstance(v, str) and "," in v else v

def normalize(doc):
    pd = {k:v for d in doc.get("product_details", []) for k,v in d.items()}
    attributes = {
        "style_code": pd.get("Style Code"),
        "closure": arr(pd.get("Closure")),
        "pockets": pd.get("Pockets"),
        "fabric": pd.get("Fabric"),
        "pattern": pd.get("Pattern"),
        "color": pd.get("Color"),
        "size": None
    }
    category_main = "clothing_and_accessories"  # derive per your taxonomy
    category_leaf = to_lc(doc.get("sub_category") or "")
    upd = {
        "price_inr": doc.get("selling_price_numeric"),
        "mrp_inr": doc.get("actual_price_numeric"),
        "rating_avg": doc.get("average_rating_numeric"),
        "attributes": attributes,
        "category_main": category_main,
        "category_leaf": category_leaf,
        "brand_lc": to_lc(doc.get("brand")),
        "color_lc": to_lc(attributes.get("color")),
        "title_autocomplete": doc.get("title")
    }
    return upd

ops=[]
for d in col.find({}, {"_id":1,"product_details":1,"sub_category":1,"brand":1,
                       "selling_price_numeric":1,"actual_price_numeric":1,
                       "average_rating_numeric":1,"title":1}):
    ops.append({"updateOne":{"filter":{"_id":d["_id"]},"update":{"$set": normalize(d)}}})
if ops: col.bulkWrite(ops)


Atlas Search Indexes
1) Vector index (name: avs_products_v1)
{
  "fields": [
    { "type": "vector", "path": "embedding", "numDimensions": 1536, "similarity": "cosine" },
    { "type": "filter", "path": "brand_lc" },
    { "type": "filter", "path": "category_main" },
    { "type": "filter", "path": "category_leaf" },
    { "type": "filter", "path": "out_of_stock" },
    { "type": "filter", "path": "color_lc" },
    { "type": "filter", "path": "price_inr" },
    { "type": "filter", "path": "rating_avg" }
  ]
}


2) Text/BM25 + Autocomplete (name: text_products_v1)
{
  "mappings": {
    "dynamic": false,
    "fields": {
      "title": { "type": "string" },
      "description": { "type": "string" },
      "brand": { "type": "string", "analyzer": "keyword" },
      "brand_lc": { "type": "string", "analyzer": "keyword" },
      "category_main": { "type": "string", "analyzer": "keyword" },
      "category_leaf": { "type": "string", "analyzer": "keyword" },
      "color_lc": { "type": "string", "analyzer": "keyword" },
      "attributes": {
        "type": "document",
        "fields": {
          "fabric": { "type": "string" },
          "pattern": { "type": "string" }
        }
      },
      "title_autocomplete": { "type": "string", "analyzer": "autocomplete" }
    }
  },
  "analyzers": [
    { "name": "autocomplete", "tokenizer": "edgeGram", "tokenFilters": ["lowercase"] }
  ],
  "synonyms": [
    { "name": "retail_syns", "source": { "collection": "synonyms", "fields": ["from","to"] } }
  ]
}

3) B-tree indexes (normal MongoDB)
db.products.createIndex({ category_main:1, category_leaf:1, out_of_stock:1, price_inr:1 });
db.products.createIndex({ brand_lc:1 });
db.products.createIndex({ color_lc:1 });



Query Parsing (rules-first)
Goal: extract budget, color, brand, category hints; the residual text is what we embed.
import re
from pydantic import BaseModel
from typing import Optional, Dict, Any

COLORS = {"red","blue","green","black","white","grey","gray","navy","maroon","pink","beige","brown"}

class ParsedQuery(BaseModel):
    query_text: str
    brand: Optional[str] = None
    color: Optional[str] = None
    category_main: Optional[str] = None
    category_leaf: Optional[str] = None
    budget_max: Optional[int] = None
    budget_min: Optional[int] = None
    in_stock_only: bool = True

def parse_query(q: str) -> ParsedQuery:
    q0, qlc = q.strip(), q.strip().lower()
    m = re.search(r"(?:under|below|<=?)\s*₹?\s*([0-9,]+)", qlc) or re.search(r"₹\s*([0-9,]+)", qlc)
    budget_max = int(m.group(1).replace(",","")) if m else None
    m2 = re.search(r"(?:above|over|>=?)\s*₹?\s*([0-9,]+)", qlc)
    budget_min = int(m2.group(1).replace(",","")) if m2 else None

    color = next((c for c in COLORS if re.search(rf"\b{c}\b", qlc)), None)

    brand = None
    m3 = re.search(r"\bfor\s+([A-Z][a-z0-9]+)\b", q) or re.search(r"\bby\s+([A-Z][a-z0-9]+)\b", q)
    if m3: brand = m3.group(1)

    category_main = category_leaf = None
    if "track pant" in qlc or "track pants" in qlc:
        category_main, category_leaf = "clothing_and_accessories", "bottomwear"

    residual = q0
    for t in filter(None, [str(budget_max), str(budget_min), color, brand]):
        residual = re.sub(re.escape(t), "", residual, flags=re.IGNORECASE)

    return ParsedQuery(
        query_text=residual.strip() or q0,
        brand=brand, color=color,
        category_main=category_main, category_leaf=category_leaf,
        budget_max=budget_max, budget_min=budget_min
    )

Embedding (OpenAI, 1536-dim)
Use the same model for items and queries.
from openai import OpenAI
oai = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def embed_query(text: str) -> list[float]:
    return oai.embeddings.create(
        model="text-embedding-3-small",
        input=text
    ).data[0].embedding


Filter Builder (Mongo)
def build_filter(pq: ParsedQuery) -> Dict[str, Any]:
    f = [{"out_of_stock": False}] if pq.in_stock_only else []
    if pq.category_main: f.append({"category_main": pq.category_main})
    if pq.category_leaf: f.append({"category_leaf": pq.category_leaf})
    if pq.brand: f.append({"brand_lc": pq.brand.lower()})
    if pq.color: f.append({"color_lc": pq.color})
    if pq.budget_max: f.append({"price_inr": {"$lte": pq.budget_max}})
    if pq.budget_min: f.append({"price_inr": {"$gte": pq.budget_min}})
    return {"$and": f} if f else {}



Hybrid Retrieval Pipeline (MongoDB aggregation)
- Vector branch for semantic recall.
- Keyword branch for lexical precision + autocomplete/synonyms.
- Combine with weighted score; return enough docs for optional reranking.

from pymongo import MongoClient

client = MongoClient(os.getenv("MONGODB_URI"))
col = client.db.products

def search_products(user_query: str, page: int = 1, page_size: int = 20):
    pq = parse_query(user_query)
    qvec = embed_query(pq.query_text)
    FILTER = build_filter(pq)

    pipeline = [
      {"$facet": {
        "vector": [
          {"$vectorSearch": {
            "index": "avs_products_v1",
            "path": "embedding",
            "queryVector": qvec,
            "numCandidates": 200,
            "limit": 60,
            "filter": FILTER
          }},
          {"$addFields": {"semanticScore": {"$meta":"vectorSearchScore"}}}
        ],
        "keyword": [
          {"$search": {
            "index": "text_products_v1",
            "compound": {
              "should": [
                {"text": {"query": pq.query_text, "path": ["title","description"], "synonym":"retail_syns"}},
                {"autocomplete": {"query": user_query, "path": "title_autocomplete"}}
              ]
            }
          }},
          {"$match": FILTER},
          {"$addFields": {"keywordScore": {"$meta":"searchScore"}}},
          {"$limit": 60}
        ]
      }},
      {"$project": {"combined": {"$concatArrays": ["$vector","$keyword"]}}},
      {"$unwind": "$combined"},
      {"$replaceRoot": {"newRoot": "$combined"}},
      {"$addFields": {
        "score": {
          "$add": [
            {"$multiply":[{"$ifNull":["$semanticScore",0]}, 0.7]},
            {"$multiply":[{"$ifNull":["$keywordScore",0]}, 0.3]},
            {"$multiply":[{"$ifNull":["$popularity_score",0]}, 0.1]}
          ]
        }
      }},
      {"$sort": {"score": -1, "_id": 1}},
      {"$skip": (page-1)*page_size},
      {"$limit": page_size},
      {"$project": {
        "_id": 1, "title":1, "brand":1, "price_inr":1, "mrp_inr":1,
        "rating_avg":1, "images":1, "category_main":1, "category_leaf":1,
        "attributes":1, "score":1, "semanticScore":1, "keywordScore":1
      }}
    ]
    return list(col.aggregate(pipeline))

Reranking (Cohere)
Apply to top 40–60; return top 20.
from cohere import Client as Cohere
co = Cohere(api_key=os.getenv("COHERE_API_KEY"))

def rerank(query: str, docs: list[dict], top_n: int = 20):
    texts = [
      f"{d.get('title','')} — {d.get('brand','')} — ₹{d.get('price_inr')} — "
      f"{d.get('attributes',{}).get('fabric','')} — {d.get('attributes',{}).get('color','')}"
      for d in docs
    ]
    rr = co.rerank(model="rerank-3", query=query, documents=texts, top_n=top_n)
    return [docs[r.index] for r in rr.results]



Facets (for filters UI)
db.products.aggregate([
  {
    $searchMeta: {
      index: "text_products_v1",
      facet: {
        operator: { text: { query: "<user text>", path: ["title","description"] } },
        facets: {
          brandFacet: { type: "string", path: "brand_lc", numBuckets: 20 },
          colorFacet: { type: "string", path: "color_lc", numBuckets: 12 },
          priceFacet: {
            type: "number",
            path: "price_inr",
            boundaries: [0,500,1000,1500,2000,3000,5000,10000],
            default: "other"
          }
        }
      }
    }
  }
])



FastAPI Endpoint (spec)
Implement GET /search?q=&page=&page_size= that:

1. Calls search_products(q, page, page_size).

2. Optionally reranks the returned list.

3. Responds with { query, page, page_size, total_estimate?, results: [...] }.

Return each result with: _id, title, brand, price_inr, mrp_inr, rating_avg, images[0], category_leaf, attributes.color, scores.


Do / Don’t
Do
    Keep one embedding model (text-embedding-3-small) for both items and queries.

    Re-embed a product only when openai_embedding_text-relevant fields change.

    Log query, top-N, clicks, and later add popularity_score.


Don’t

    Mix embeddings from different models without re-embedding the whole corpus.

    Store numbers as strings.

    Depend only on vector search; always keep hybrid.



Smoke Tests (prompt Copilot to write these)
    Query: “blue track pants under ₹700” → color filter = blue, price_inr <= 700, category_leaf=bottomwear.

    Query: “gift for my mom who loves gardening” → no hard filters, semantic recall should include gardening-tagged or semantically related items.

    Query: “Samsung phone with 8 GB RAM and 5G” → if phones present, filters map to attributes.ram_gb >= 8, attributes.supports_5g=true, brand_lc='samsung' (extend parser for numbers/booleans when you add electronics).

Tuning Notes
Start with weights: semantic 0.7, keyword 0.3, popularity 0.1 (if available).

Increase numCandidates (e.g., 400) if recall is low; keep limit ~60 for reranking cost.

Use $search fuzzy options in keyword branch if typos are common.

You (Copilot) should:

    Generate missing code files (parsers, routes, index JSONs).

    Propose migration scripts and tests.

    Keep code idempotent and production-ready, with clear env vars and error handling.



